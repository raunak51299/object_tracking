{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "    def __init__(self, weights_path=\"dnn_model/yolov4.weights\", cfg_path=\"dnn_model/yolov4.cfg\"):\n",
    "        # Print loading messages\n",
    "        print(\"Loading Object Detection\")\n",
    "        print(\"Running opencv dnn with YOLOv4\")\n",
    "        \n",
    "        # Set the Non-Maximum Suppression threshold, Confidence threshold, and Image size\n",
    "        self.nmsThreshold = 0.4\n",
    "        self.confThreshold = 0.5\n",
    "        self.image_size = 608\n",
    "\n",
    "        # Load the YOLOv4 model\n",
    "        net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "\n",
    "        # Enable GPU acceleration with CUDA\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "        self.model = cv2.dnn_DetectionModel(net)\n",
    "\n",
    "        # Initialize the list of class names and load them\n",
    "        self.classes = []\n",
    "        self.load_class_names()\n",
    "        \n",
    "        # Assign random colors for each class\n",
    "        self.colors = np.random.uniform(0, 255, size=(80, 3))\n",
    "\n",
    "        # Set input parameters for the model\n",
    "        self.model.setInputParams(size=(self.image_size, self.image_size), scale=1/255)\n",
    "\n",
    "    def load_class_names(self, classes_path=\"dnn_model/classes.txt\"):\n",
    "        # Load class names from a text file\n",
    "        with open(classes_path, \"r\") as file_object:\n",
    "            for class_name in file_object.readlines():\n",
    "                class_name = class_name.strip()\n",
    "                self.classes.append(class_name)\n",
    "\n",
    "        # Assign random colors for each class\n",
    "        self.colors = np.random.uniform(0, 255, size=(80, 3))\n",
    "        return self.classes\n",
    "\n",
    "    def detect(self, frame):\n",
    "        # Perform object detection on a given frame\n",
    "        return self.model.detect(frame, nmsThreshold=self.nmsThreshold, confThreshold=self.confThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Object Detection\n",
      "Running opencv dnn with YOLOv4\n"
     ]
    }
   ],
   "source": [
    "# Initialize Object Detection\n",
    "od = ObjectDetection()\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"traffic.mp4\")\n",
    "\n",
    "# Initialize count\n",
    "count = 0\n",
    "# Initialize list to store center points of detected objects in the previous frame\n",
    "center_points_prev_frame = []\n",
    "\n",
    "# Initialize dictionary to store tracking objects\n",
    "tracking_objects = {}\n",
    "# Initialize tracking id\n",
    "track_id = 0\n",
    "\n",
    "# Loop over the frames of the video\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    # Increment the frame count\n",
    "    count += 1\n",
    "    # If the frame could not be grabbed, then we have reached the end of the video\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize list to store center points of detected objects in the current frame\n",
    "    center_points_cur_frame = []\n",
    "\n",
    "    # Detect objects on the current frame\n",
    "    (class_ids, scores, boxes) = od.detect(frame)\n",
    "    # Loop over the bounding boxes\n",
    "    for box in boxes:\n",
    "        # Extract the bounding box coordinates\n",
    "        (x, y, w, h) = box\n",
    "        # Compute the center of the bounding box\n",
    "        cx = int((x + x + w) / 2)\n",
    "        cy = int((y + y + h) / 2)\n",
    "        # Add the center point to the list\n",
    "        center_points_cur_frame.append((cx, cy))\n",
    "\n",
    "        # Draw the bounding box on the frame\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # If this is one of the first two frames, compare the center points of the current and previous frames\n",
    "    if count <= 2:\n",
    "        for pt in center_points_cur_frame:\n",
    "            for pt2 in center_points_prev_frame:\n",
    "                # Compute the Euclidean distance between the two points\n",
    "                distance = math.hypot(pt2[0] - pt[0], pt2[1] - pt[1])\n",
    "\n",
    "                # If the distance is less than 20 pixels, add the point to the tracking objects\n",
    "                if distance < 20:\n",
    "                    tracking_objects[track_id] = pt\n",
    "                    track_id += 1\n",
    "    else:\n",
    "        # For the rest of the frames, update the tracking objects\n",
    "        tracking_objects_copy = tracking_objects.copy()\n",
    "        center_points_cur_frame_copy = center_points_cur_frame.copy()\n",
    "\n",
    "        for object_id, pt2 in tracking_objects_copy.items():\n",
    "            object_exists = False\n",
    "            for pt in center_points_cur_frame_copy:\n",
    "                # Compute the Euclidean distance between the two points\n",
    "                distance = math.hypot(pt2[0] - pt[0], pt2[1] - pt[1])\n",
    "\n",
    "                # If the distance is less than 20 pixels, update the position of the tracking object\n",
    "                if distance < 20:\n",
    "                    tracking_objects[object_id] = pt\n",
    "                    object_exists = True\n",
    "                    if pt in center_points_cur_frame:\n",
    "                        center_points_cur_frame.remove(pt)\n",
    "                    continue\n",
    "\n",
    "            # If the tracking object does not exist in the current frame, remove it\n",
    "            if not object_exists:\n",
    "                tracking_objects.pop(object_id)\n",
    "\n",
    "        # Add new tracking objects found in the current frame\n",
    "        for pt in center_points_cur_frame:\n",
    "            tracking_objects[track_id] = pt\n",
    "            track_id += 1\n",
    "\n",
    "    # Draw the tracking objects on the frame\n",
    "    for object_id, pt in tracking_objects.items():\n",
    "        cv2.circle(frame, pt, 5, (0, 0, 255), -1)\n",
    "        cv2.putText(frame, str(object_id), (pt[0], pt[1] - 7), 0, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Update the list of center points for the next iteration\n",
    "    center_points_prev_frame = center_points_cur_frame.copy()\n",
    "\n",
    "    # If the 'q' key is pressed, break from the loop\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27: \n",
    "        break\n",
    "\n",
    "# Release the video file\n",
    "cap.release()\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
